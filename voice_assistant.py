#!/usr/bin/env python3
"""
è¯­éŸ³åŠ©æ‰‹ - å¯¹æ¥ Claude Code CLI
æµç¨‹: å½•éŸ³ â†’ Whisperè¯†åˆ« â†’ Claudeå›å¤ â†’ Edge TTSæœ—è¯»
"""

import subprocess
import tempfile
import asyncio
import sys
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write as write_wav

# é…ç½®
SAMPLE_RATE = 16000
WHISPER_MODEL = "base"  # tiny/base/small/medium/large
TTS_VOICE = "zh-CN-XiaoyiNeural"  # å°è‰º
TTS_RATE = "-15%"  # è¯­é€Ÿ: -50%~+50%ï¼Œè´Ÿæ•°æ…¢ï¼Œæ­£æ•°å¿«


class VoiceAssistant:
    def __init__(self):
        self.whisper_model = None

    def load_whisper(self):
        """æ‡’åŠ è½½ Whisper æ¨¡å‹"""
        if self.whisper_model is None:
            print("ğŸ”„ åŠ è½½ Whisper æ¨¡å‹...")
            from faster_whisper import WhisperModel
            self.whisper_model = WhisperModel(WHISPER_MODEL, compute_type="int8")
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        return self.whisper_model

    def record_audio(self, duration=None):
        """å½•éŸ³ - æŒ‰å›è½¦åœæ­¢"""
        print("\nğŸ¤ å¼€å§‹å½•éŸ³... (æŒ‰å›è½¦åœæ­¢)")

        frames = []
        recording = True

        def callback(indata, frame_count, time_info, status):
            if recording:
                frames.append(indata.copy())

        stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype=np.float32,
            callback=callback
        )

        with stream:
            input()  # ç­‰å¾…å›è½¦
            recording = False

        if not frames:
            return None

        audio = np.concatenate(frames, axis=0)
        print(f"âœ… å½•éŸ³å®Œæˆ ({len(audio)/SAMPLE_RATE:.1f}ç§’)")
        return audio

    def transcribe(self, audio):
        """è¯­éŸ³è¯†åˆ«"""
        print("ğŸ”„ è¯†åˆ«ä¸­...")
        model = self.load_whisper()

        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            audio_int16 = (audio * 32767).astype(np.int16)
            write_wav(f.name, SAMPLE_RATE, audio_int16)

            segments, info = model.transcribe(f.name, language="zh")
            text = "".join([seg.text for seg in segments])

        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}")
        return text.strip()

    def ask_claude(self, question):
        """è°ƒç”¨ Claude Code CLI"""
        print("ğŸ¤– Claude æ€è€ƒä¸­...")

        try:
            result = subprocess.run(
                ["claude", "-p", question],
                capture_output=True,
                text=True,
                timeout=60
            )
            response = result.stdout.strip()
            print(f"ğŸ’¬ Claude: {response[:200]}{'...' if len(response) > 200 else ''}")
            return response
        except subprocess.TimeoutExpired:
            return "æŠ±æ­‰ï¼Œå›å¤è¶…æ—¶äº†"
        except Exception as e:
            return f"å‡ºé”™äº†: {e}"

    async def speak(self, text):
        """Edge TTS æœ—è¯»"""
        import edge_tts

        print("ğŸ”Š æœ—è¯»ä¸­...")
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
            communicate = edge_tts.Communicate(text, TTS_VOICE, rate=TTS_RATE)
            await communicate.save(f.name)
            subprocess.run(["afplay", f.name])

    async def chat_once(self):
        """å•æ¬¡å¯¹è¯"""
        # 1. å½•éŸ³
        audio = self.record_audio()
        if audio is None or len(audio) < SAMPLE_RATE * 0.5:
            print("âš ï¸  å½•éŸ³å¤ªçŸ­ï¼Œè·³è¿‡")
            return

        # 2. è¯†åˆ«
        text = self.transcribe(audio)
        if not text:
            print("âš ï¸  æœªè¯†åˆ«åˆ°å†…å®¹")
            return

        # 3. é—® Claude
        response = self.ask_claude(text)

        # 4. æœ—è¯»
        await self.speak(response)

    async def run(self):
        """ä¸»å¾ªç¯"""
        print("=" * 50)
        print("ğŸ™ï¸  è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨")
        print("   æŒ‰å›è½¦å¼€å§‹å½•éŸ³ï¼Œå†æŒ‰å›è½¦åœæ­¢")
        print("   è¾“å…¥ 'q' é€€å‡º")
        print("=" * 50)

        while True:
            cmd = input("\næŒ‰å›è½¦å¼€å§‹å¯¹è¯ (qé€€å‡º): ").strip().lower()
            if cmd == 'q':
                print("ğŸ‘‹ å†è§!")
                break

            await self.chat_once()


async def main():
    assistant = VoiceAssistant()
    await assistant.run()


if __name__ == "__main__":
    asyncio.run(main())
