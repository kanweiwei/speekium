#!/usr/bin/env python3
"""
è¯­éŸ³åŠ©æ‰‹ - å¯¹æ¥ Claude Code CLI
æµç¨‹: [å”¤é†’è¯/æŒ‰é”®] â†’ å½•éŸ³ â†’ Whisperè¯†åˆ« â†’ Claudeæµå¼å›å¤ â†’ è¾¹ç”Ÿæˆè¾¹æœ—è¯»
"""

import subprocess
import tempfile
import asyncio
import sys
import os
import json
import re
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write as write_wav

# é…ç½®
SAMPLE_RATE = 16000
WHISPER_MODEL = "base"  # tiny/base/small/medium/large
TTS_VOICE = "zh-CN-XiaoyiNeural"  # å°è‰º
TTS_RATE = "-15%"  # è¯­é€Ÿ
USE_WAKE_WORD = True  # æ˜¯å¦ä½¿ç”¨å”¤é†’è¯ï¼ˆTrue=å”¤é†’è¯ï¼ŒFalse=æŒ‰å›è½¦ï¼‰
WAKE_WORD = "hey_jarvis"
WAKE_THRESHOLD = 0.5
SILENCE_DURATION = 2.5  # é™éŸ³å¤šå°‘ç§’ååœæ­¢å½•éŸ³
USE_STREAMING = True  # æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆè¾¹ç”Ÿæˆè¾¹æœ—è¯»ï¼‰

# Claude ç³»ç»Ÿæç¤ºè¯ï¼ˆä¼˜åŒ–è¯­éŸ³è¾“å‡ºï¼‰
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åŠ©æ‰‹ï¼Œè¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. ç”¨å£è¯­åŒ–çš„ä¸­æ–‡å›ç­”ï¼Œé€‚åˆæœ—è¯»
2. ä¸è¦ä½¿ç”¨ markdown æ ¼å¼ã€ä»£ç å—ã€åˆ—è¡¨ç¬¦å·
3. ä¸è¦ä½¿ç”¨ç‰¹æ®Šç¬¦å·å¦‚ *ã€#ã€`ã€- ç­‰
4. æ•°å­—ç”¨ä¸­æ–‡è¡¨è¾¾ï¼Œå¦‚"ä¸‰ç‚¹äº”"è€Œä¸æ˜¯"3.5"
5. è¯­æ°”è‡ªç„¶å‹å¥½ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ ·"""


class VoiceAssistant:
    def __init__(self):
        self.whisper_model = None
        self.wake_model = None

    def load_whisper(self):
        if self.whisper_model is None:
            print("ğŸ”„ åŠ è½½ Whisper æ¨¡å‹...", flush=True)
            from faster_whisper import WhisperModel
            self.whisper_model = WhisperModel(WHISPER_MODEL, compute_type="int8")
            print("âœ… Whisper æ¨¡å‹åŠ è½½å®Œæˆ", flush=True)
        return self.whisper_model

    def load_wake_model(self):
        if self.wake_model is None:
            print("ğŸ”„ åŠ è½½å”¤é†’è¯æ¨¡å‹...", flush=True)
            from openwakeword.model import Model
            self.wake_model = Model(
                wakeword_models=[WAKE_WORD],
                inference_framework='onnx'
            )
            print(f"âœ… å”¤é†’è¯æ¨¡å‹åŠ è½½å®Œæˆ", flush=True)
        return self.wake_model

    def wait_for_wake_word(self):
        """ç­‰å¾…å”¤é†’è¯"""
        model = self.load_wake_model()
        model.reset()
        sd.sleep(500)

        print(f"\nğŸ‘‚ ç­‰å¾…å”¤é†’è¯ 'Hey Jarvis'...", flush=True)

        chunk_size = 1280
        detected = False

        def callback(indata, frames, time_info, status):
            nonlocal detected
            if detected:
                return
            audio_float = indata[:, 0]
            audio_int16 = (audio_float * 32767).astype(np.int16)
            prediction = model.predict(audio_int16)
            score = prediction[WAKE_WORD]
            if score > WAKE_THRESHOLD:
                detected = True
                print(f"âœ¨ æ£€æµ‹åˆ°å”¤é†’è¯! (ç½®ä¿¡åº¦: {score:.2f})", flush=True)

        with sd.InputStream(
            samplerate=SAMPLE_RATE, channels=1, dtype=np.float32,
            blocksize=chunk_size, callback=callback
        ):
            while not detected:
                sd.sleep(100)

        return True

    def wait_for_key(self):
        """ç­‰å¾…æŒ‰é”®"""
        input("\næŒ‰å›è½¦å¼€å§‹å½•éŸ³...")
        return True

    def record_audio_manual(self):
        """å½•éŸ³ - æŒ‰å›è½¦åœæ­¢"""
        print("ğŸ¤ å¼€å§‹å½•éŸ³... (æŒ‰å›è½¦åœæ­¢)", flush=True)

        frames = []
        recording = True

        def callback(indata, frame_count, time_info, status):
            if recording:
                frames.append(indata.copy())

        stream = sd.InputStream(
            samplerate=SAMPLE_RATE, channels=1, dtype=np.float32, callback=callback
        )

        with stream:
            input()
            recording = False

        if not frames:
            return None

        audio = np.concatenate(frames, axis=0)
        print(f"âœ… å½•éŸ³å®Œæˆ ({len(audio)/SAMPLE_RATE:.1f}ç§’)", flush=True)
        return audio

    def record_audio_auto(self, max_duration=10, silence_threshold=0.01, silence_duration=SILENCE_DURATION):
        """å½•éŸ³ - é™éŸ³è‡ªåŠ¨åœæ­¢"""
        print("ğŸ¤ è¯·è¯´è¯... (é™éŸ³è‡ªåŠ¨åœæ­¢)", flush=True)

        frames = []
        silent_chunks = 0
        chunk_duration = 0.1
        max_silent_chunks = int(silence_duration / chunk_duration)

        def callback(indata, frame_count, time_info, status):
            nonlocal silent_chunks
            frames.append(indata.copy())
            volume = np.abs(indata).mean()
            if volume < silence_threshold:
                silent_chunks += 1
            else:
                silent_chunks = 0

        with sd.InputStream(
            samplerate=SAMPLE_RATE, channels=1, dtype=np.float32,
            callback=callback, blocksize=int(SAMPLE_RATE * chunk_duration)
        ):
            while True:
                sd.sleep(100)
                if silent_chunks >= max_silent_chunks and len(frames) > 10:
                    print("ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢å½•éŸ³", flush=True)
                    break
                if len(frames) * chunk_duration >= max_duration:
                    print("â±ï¸ è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿", flush=True)
                    break

        if not frames:
            return None

        audio = np.concatenate(frames, axis=0)
        print(f"âœ… å½•éŸ³å®Œæˆ ({len(audio)/SAMPLE_RATE:.1f}ç§’)", flush=True)
        return audio

    def transcribe(self, audio):
        print("ğŸ”„ è¯†åˆ«ä¸­...", flush=True)
        model = self.load_whisper()
        tmp_file = None

        try:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                tmp_file = f.name
                audio_int16 = (audio * 32767).astype(np.int16)
                write_wav(tmp_file, SAMPLE_RATE, audio_int16)
                segments, info = model.transcribe(tmp_file, language="zh")
                text = "".join([seg.text for seg in segments])
        finally:
            if tmp_file and os.path.exists(tmp_file):
                os.remove(tmp_file)

        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}", flush=True)
        return text.strip()

    def ask_claude(self, question):
        """éæµå¼è°ƒç”¨ Claude"""
        print("ğŸ¤– Claude æ€è€ƒä¸­...", flush=True)
        try:
            result = subprocess.run(
                [
                    "claude", "-p", question,
                    "--dangerously-skip-permissions",
                    "--system-prompt", SYSTEM_PROMPT
                ],
                capture_output=True, text=True, timeout=120
            )
            response = result.stdout.strip()
            print(f"ğŸ’¬ Claude: {response}", flush=True)
            return response
        except subprocess.TimeoutExpired:
            return "æŠ±æ­‰ï¼Œå›å¤è¶…æ—¶äº†"
        except Exception as e:
            return f"å‡ºé”™äº†: {e}"

    async def ask_claude_stream(self, question):
        """æµå¼è°ƒç”¨ Claudeï¼Œè¿”å›å¥å­ç”Ÿæˆå™¨"""
        print("ğŸ¤– Claude æ€è€ƒä¸­...", flush=True)

        cmd = [
            "claude", "-p", question,
            "--dangerously-skip-permissions",
            "--system-prompt", SYSTEM_PROMPT,
            "--output-format", "stream-json",
            "--include-partial-messages",
            "--verbose"
        ]

        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        buffer = ""
        full_response = ""
        sentence_endings = re.compile(r'([ã€‚ï¼ï¼Ÿ\n])')

        async for line in process.stdout:
            try:
                data = json.loads(line.decode('utf-8'))

                # æå–æµå¼æ–‡æœ¬ç‰‡æ®µ
                if data.get("type") == "stream_event":
                    event = data.get("event", {})
                    if event.get("type") == "content_block_delta":
                        delta = event.get("delta", {})
                        if delta.get("type") == "text_delta":
                            text = delta.get("text", "")
                            buffer += text
                            full_response += text

                            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´å¥å­
                            while True:
                                match = sentence_endings.search(buffer)
                                if match:
                                    end_pos = match.end()
                                    sentence = buffer[:end_pos].strip()
                                    buffer = buffer[end_pos:]
                                    if sentence:
                                        print(f"ğŸ—£ï¸  {sentence}", flush=True)
                                        yield sentence
                                else:
                                    break

            except json.JSONDecodeError:
                continue
            except Exception as e:
                print(f"âš ï¸ è§£æé”™è¯¯: {e}", flush=True)
                continue

        # å¤„ç†å‰©ä½™å†…å®¹
        if buffer.strip():
            print(f"ğŸ—£ï¸  {buffer.strip()}", flush=True)
            yield buffer.strip()

        await process.wait()

    async def generate_audio(self, text):
        """ç”Ÿæˆ TTS éŸ³é¢‘æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„"""
        import edge_tts
        try:
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
                tmp_file = f.name
                communicate = edge_tts.Communicate(text, TTS_VOICE, rate=TTS_RATE)
                await communicate.save(tmp_file)
                return tmp_file
        except Exception as e:
            print(f"âš ï¸ TTS ç”Ÿæˆå¤±è´¥: {e}", flush=True)
            return None

    async def play_audio(self, tmp_file):
        """æ’­æ”¾éŸ³é¢‘æ–‡ä»¶å¹¶æ¸…ç†ï¼ˆå¼‚æ­¥ï¼‰"""
        if tmp_file and os.path.exists(tmp_file):
            try:
                process = await asyncio.create_subprocess_exec("afplay", tmp_file)
                await process.wait()
            finally:
                os.remove(tmp_file)

    async def speak(self, text):
        """TTS æœ—è¯»ï¼ˆå•å¥ï¼‰"""
        tmp_file = await self.generate_audio(text)
        await self.play_audio(tmp_file)

    async def chat_once(self):
        """å•æ¬¡å¯¹è¯ - éæµå¼"""
        if USE_WAKE_WORD:
            audio = self.record_audio_auto()
        else:
            audio = self.record_audio_manual()

        if audio is None or len(audio) < SAMPLE_RATE * 0.5:
            print("âš ï¸  å½•éŸ³å¤ªçŸ­ï¼Œè·³è¿‡", flush=True)
            return

        text = self.transcribe(audio)
        if not text:
            print("âš ï¸  æœªè¯†åˆ«åˆ°å†…å®¹", flush=True)
            return

        response = self.ask_claude(text)
        await self.speak(response)

    async def chat_once_stream(self):
        """å•æ¬¡å¯¹è¯ - æµå¼ï¼ˆè¾¹ç”Ÿæˆè¾¹æœ—è¯»ï¼ŒéŸ³é¢‘é¢„ç”Ÿæˆï¼‰"""
        if USE_WAKE_WORD:
            audio = self.record_audio_auto()
        else:
            audio = self.record_audio_manual()

        if audio is None or len(audio) < SAMPLE_RATE * 0.5:
            print("âš ï¸  å½•éŸ³å¤ªçŸ­ï¼Œè·³è¿‡", flush=True)
            return

        text = self.transcribe(audio)
        if not text:
            print("âš ï¸  æœªè¯†åˆ«åˆ°å†…å®¹", flush=True)
            return

        print("ğŸ”Š æµå¼æœ—è¯»ä¸­...", flush=True)

        # ä½¿ç”¨é˜Ÿåˆ—å®ç°æµæ°´çº¿ï¼šTTSç”Ÿæˆ -> é˜Ÿåˆ— -> æ’­æ”¾
        audio_queue = asyncio.Queue()

        async def generate_worker():
            """ç”ŸæˆéŸ³é¢‘å¹¶æ”¾å…¥é˜Ÿåˆ—"""
            async for sentence in self.ask_claude_stream(text):
                if sentence:
                    audio_file = await self.generate_audio(sentence)
                    if audio_file:
                        await audio_queue.put(audio_file)
            await audio_queue.put(None)  # ç»“æŸä¿¡å·

        async def play_worker():
            """ä»é˜Ÿåˆ—å–å‡ºéŸ³é¢‘æ’­æ”¾"""
            while True:
                audio_file = await audio_queue.get()
                if audio_file is None:
                    break
                await self.play_audio(audio_file)

        # å¹¶è¡Œè¿è¡Œç”Ÿæˆå’Œæ’­æ”¾
        await asyncio.gather(generate_worker(), play_worker())

    async def run(self):
        print("=" * 50, flush=True)
        print("ğŸ™ï¸  è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨", flush=True)
        if USE_WAKE_WORD:
            print(f"   å”¤é†’è¯: 'Hey Jarvis'", flush=True)
        else:
            print("   æŒ‰å›è½¦å¼€å§‹å½•éŸ³ï¼Œå†æŒ‰å›è½¦åœæ­¢", flush=True)
        if USE_STREAMING:
            print("   æ¨¡å¼: æµå¼è¾“å‡ºï¼ˆè¾¹ç”Ÿæˆè¾¹æœ—è¯»ï¼‰", flush=True)
        print("   Ctrl+C é€€å‡º", flush=True)
        print("=" * 50, flush=True)

        # é¢„åŠ è½½æ¨¡å‹
        if USE_WAKE_WORD:
            self.load_wake_model()
        self.load_whisper()

        try:
            while True:
                if USE_WAKE_WORD:
                    self.wait_for_wake_word()
                    await self.speak("æˆ‘åœ¨")
                else:
                    self.wait_for_key()

                if USE_STREAMING:
                    await self.chat_once_stream()
                else:
                    await self.chat_once()

        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§!", flush=True)


async def main():
    assistant = VoiceAssistant()
    await assistant.run()


if __name__ == "__main__":
    asyncio.run(main())
