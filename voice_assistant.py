#!/usr/bin/env python3
"""
è¯­éŸ³åŠ©æ‰‹ - å¯¹æ¥ Claude Code CLI
æµç¨‹: [å”¤é†’è¯/æŒ‰é”®] â†’ å½•éŸ³ â†’ Whisperè¯†åˆ« â†’ Claudeå›å¤ â†’ Edge TTSæœ—è¯»
"""

import subprocess
import tempfile
import asyncio
import sys
import os
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write as write_wav

# é…ç½®
SAMPLE_RATE = 16000
WHISPER_MODEL = "base"  # tiny/base/small/medium/large
TTS_VOICE = "zh-CN-XiaoyiNeural"  # å°è‰º
TTS_RATE = "-15%"  # è¯­é€Ÿ
USE_WAKE_WORD = True  # æ˜¯å¦ä½¿ç”¨å”¤é†’è¯ï¼ˆTrue=å”¤é†’è¯ï¼ŒFalse=æŒ‰å›è½¦ï¼‰
WAKE_WORD = "hey_jarvis"
WAKE_THRESHOLD = 0.5
SILENCE_DURATION = 2.5  # é™éŸ³å¤šå°‘ç§’ååœæ­¢å½•éŸ³

# Claude ç³»ç»Ÿæç¤ºè¯ï¼ˆä¼˜åŒ–è¯­éŸ³è¾“å‡ºï¼‰
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åŠ©æ‰‹ï¼Œè¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. ç”¨å£è¯­åŒ–çš„ä¸­æ–‡å›ç­”ï¼Œé€‚åˆæœ—è¯»
2. ä¸è¦ä½¿ç”¨ markdown æ ¼å¼ã€ä»£ç å—ã€åˆ—è¡¨ç¬¦å·
3. ä¸è¦ä½¿ç”¨ç‰¹æ®Šç¬¦å·å¦‚ *ã€#ã€`ã€- ç­‰
4. æ•°å­—ç”¨ä¸­æ–‡è¡¨è¾¾ï¼Œå¦‚"ä¸‰ç‚¹äº”"è€Œä¸æ˜¯"3.5"
5. è¯­æ°”è‡ªç„¶å‹å¥½ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ ·"""


class VoiceAssistant:
    def __init__(self):
        self.whisper_model = None
        self.wake_model = None

    def load_whisper(self):
        if self.whisper_model is None:
            print("ğŸ”„ åŠ è½½ Whisper æ¨¡å‹...", flush=True)
            from faster_whisper import WhisperModel
            self.whisper_model = WhisperModel(WHISPER_MODEL, compute_type="int8")
            print("âœ… Whisper æ¨¡å‹åŠ è½½å®Œæˆ", flush=True)
        return self.whisper_model

    def load_wake_model(self):
        if self.wake_model is None:
            print("ğŸ”„ åŠ è½½å”¤é†’è¯æ¨¡å‹...", flush=True)
            from openwakeword.model import Model
            self.wake_model = Model(
                wakeword_models=[WAKE_WORD],
                inference_framework='onnx'
            )
            print(f"âœ… å”¤é†’è¯æ¨¡å‹åŠ è½½å®Œæˆ", flush=True)
        return self.wake_model

    def wait_for_wake_word(self):
        """ç­‰å¾…å”¤é†’è¯"""
        model = self.load_wake_model()

        # é‡ç½®æ¨¡å‹çŠ¶æ€ï¼Œæ¸…é™¤ä¹‹å‰çš„ç¼“å­˜
        model.reset()

        # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…ä¹‹å‰çš„è¯­éŸ³è¢«è¯¯æ£€æµ‹
        sd.sleep(500)

        print(f"\nğŸ‘‚ ç­‰å¾…å”¤é†’è¯ 'Hey Jarvis'...", flush=True)

        chunk_size = 1280
        detected = False

        def callback(indata, frames, time_info, status):
            nonlocal detected
            if detected:
                return
            # è½¬æ¢ä¸º int16 æ ¼å¼ï¼ˆopenwakeword éœ€è¦ï¼‰
            audio_float = indata[:, 0]
            audio_int16 = (audio_float * 32767).astype(np.int16)
            prediction = model.predict(audio_int16)
            score = prediction[WAKE_WORD]
            if score > WAKE_THRESHOLD:
                detected = True
                print(f"âœ¨ æ£€æµ‹åˆ°å”¤é†’è¯! (ç½®ä¿¡åº¦: {score:.2f})", flush=True)

        with sd.InputStream(
            samplerate=SAMPLE_RATE, channels=1, dtype=np.float32,
            blocksize=chunk_size, callback=callback
        ):
            while not detected:
                sd.sleep(100)

        return True

    def wait_for_key(self):
        """ç­‰å¾…æŒ‰é”®"""
        input("\næŒ‰å›è½¦å¼€å§‹å½•éŸ³...")
        return True

    def record_audio_manual(self):
        """å½•éŸ³ - æŒ‰å›è½¦åœæ­¢"""
        print("ğŸ¤ å¼€å§‹å½•éŸ³... (æŒ‰å›è½¦åœæ­¢)", flush=True)

        frames = []
        recording = True

        def callback(indata, frame_count, time_info, status):
            if recording:
                frames.append(indata.copy())

        stream = sd.InputStream(
            samplerate=SAMPLE_RATE, channels=1, dtype=np.float32, callback=callback
        )

        with stream:
            input()
            recording = False

        if not frames:
            return None

        audio = np.concatenate(frames, axis=0)
        print(f"âœ… å½•éŸ³å®Œæˆ ({len(audio)/SAMPLE_RATE:.1f}ç§’)", flush=True)
        return audio

    def record_audio_auto(self, max_duration=10, silence_threshold=0.01, silence_duration=SILENCE_DURATION):
        """å½•éŸ³ - é™éŸ³è‡ªåŠ¨åœæ­¢"""
        print("ğŸ¤ è¯·è¯´è¯... (é™éŸ³è‡ªåŠ¨åœæ­¢)", flush=True)

        frames = []
        silent_chunks = 0
        chunk_duration = 0.1
        max_silent_chunks = int(silence_duration / chunk_duration)

        def callback(indata, frame_count, time_info, status):
            nonlocal silent_chunks
            frames.append(indata.copy())
            volume = np.abs(indata).mean()
            if volume < silence_threshold:
                silent_chunks += 1
            else:
                silent_chunks = 0

        with sd.InputStream(
            samplerate=SAMPLE_RATE, channels=1, dtype=np.float32,
            callback=callback, blocksize=int(SAMPLE_RATE * chunk_duration)
        ):
            while True:
                sd.sleep(100)
                if silent_chunks >= max_silent_chunks and len(frames) > 10:
                    print("ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢å½•éŸ³", flush=True)
                    break
                if len(frames) * chunk_duration >= max_duration:
                    print("â±ï¸ è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿", flush=True)
                    break

        if not frames:
            return None

        audio = np.concatenate(frames, axis=0)
        print(f"âœ… å½•éŸ³å®Œæˆ ({len(audio)/SAMPLE_RATE:.1f}ç§’)", flush=True)
        return audio

    def transcribe(self, audio):
        print("ğŸ”„ è¯†åˆ«ä¸­...", flush=True)
        model = self.load_whisper()
        tmp_file = None

        try:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                tmp_file = f.name
                audio_int16 = (audio * 32767).astype(np.int16)
                write_wav(tmp_file, SAMPLE_RATE, audio_int16)
                segments, info = model.transcribe(tmp_file, language="zh")
                text = "".join([seg.text for seg in segments])
        finally:
            if tmp_file and os.path.exists(tmp_file):
                os.remove(tmp_file)

        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}", flush=True)
        return text.strip()

    def ask_claude(self, question):
        print("ğŸ¤– Claude æ€è€ƒä¸­...", flush=True)
        try:
            result = subprocess.run(
                [
                    "claude", "-p", question,
                    "--dangerously-skip-permissions",
                    "--system-prompt", SYSTEM_PROMPT
                ],
                capture_output=True, text=True, timeout=120
            )
            response = result.stdout.strip()
            print(f"ğŸ’¬ Claude: {response}", flush=True)
            return response
        except subprocess.TimeoutExpired:
            return "æŠ±æ­‰ï¼Œå›å¤è¶…æ—¶äº†"
        except Exception as e:
            return f"å‡ºé”™äº†: {e}"

    async def speak(self, text):
        import edge_tts
        print("ğŸ”Š æœ—è¯»ä¸­...", flush=True)
        tmp_file = None
        try:
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
                tmp_file = f.name
                communicate = edge_tts.Communicate(text, TTS_VOICE, rate=TTS_RATE)
                await communicate.save(tmp_file)
                subprocess.run(["afplay", tmp_file])
        except Exception as e:
            print(f"âš ï¸ TTS å¤±è´¥: {e}", flush=True)
        finally:
            if tmp_file and os.path.exists(tmp_file):
                os.remove(tmp_file)

    async def chat_once(self):
        # å½•éŸ³
        if USE_WAKE_WORD:
            audio = self.record_audio_auto()
        else:
            audio = self.record_audio_manual()

        if audio is None or len(audio) < SAMPLE_RATE * 0.5:
            print("âš ï¸  å½•éŸ³å¤ªçŸ­ï¼Œè·³è¿‡", flush=True)
            return

        text = self.transcribe(audio)
        if not text:
            print("âš ï¸  æœªè¯†åˆ«åˆ°å†…å®¹", flush=True)
            return

        response = self.ask_claude(text)
        await self.speak(response)

    async def run(self):
        print("=" * 50, flush=True)
        print("ğŸ™ï¸  è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨", flush=True)
        if USE_WAKE_WORD:
            print(f"   å”¤é†’è¯: 'Hey Jarvis'", flush=True)
        else:
            print("   æŒ‰å›è½¦å¼€å§‹å½•éŸ³ï¼Œå†æŒ‰å›è½¦åœæ­¢", flush=True)
        print("   Ctrl+C é€€å‡º", flush=True)
        print("=" * 50, flush=True)

        # é¢„åŠ è½½æ¨¡å‹
        if USE_WAKE_WORD:
            self.load_wake_model()
        self.load_whisper()

        try:
            while True:
                if USE_WAKE_WORD:
                    self.wait_for_wake_word()
                    await self.speak("æˆ‘åœ¨")
                else:
                    self.wait_for_key()

                await self.chat_once()

        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§!", flush=True)


async def main():
    assistant = VoiceAssistant()
    await assistant.run()


if __name__ == "__main__":
    asyncio.run(main())
