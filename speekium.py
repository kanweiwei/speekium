#!/usr/bin/env python3
"""
Speekium - æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹
é€šè¿‡è‡ªç„¶è¯­éŸ³ä¸å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå¯¹è¯äº¤äº’
æµç¨‹: [VADæ£€æµ‹äººå£°] â†’ å½•éŸ³ â†’ SenseVoiceè¯†åˆ« â†’ LLMæµå¼å›å¤ â†’ è¾¹ç”Ÿæˆè¾¹æœ—è¯»

å½“å‰åç«¯: Claude Code CLI
è®¡åˆ’æ”¯æŒ: Ollama, OpenAI API
"""

import subprocess
import tempfile
import asyncio
import sys
import os
import json
import re
import platform
from collections import deque
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write as write_wav
import edge_tts
import torch

# é…ç½®
SAMPLE_RATE = 16000
ASR_MODEL = "iic/SenseVoiceSmall"  # SenseVoice æ¨¡å‹
TTS_VOICE = "zh-CN-XiaoyiNeural"  # å°è‰º
TTS_RATE = "-15%"  # è¯­é€Ÿ
USE_STREAMING = True  # æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆè¾¹ç”Ÿæˆè¾¹æœ—è¯»ï¼‰

# VAD é…ç½®
VAD_THRESHOLD = 0.5  # è¯­éŸ³æ£€æµ‹é˜ˆå€¼
VAD_CONSECUTIVE_THRESHOLD = 3  # è¿ç»­æ£€æµ‹åˆ°è¯­éŸ³çš„æ¬¡æ•°æ‰ç¡®è®¤å¼€å§‹è¯´è¯
VAD_PRE_BUFFER = 0.3  # é¢„ç¼“å†²æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œä¿ç•™è¯­éŸ³å¼€å§‹å‰çš„éŸ³é¢‘
MIN_SPEECH_DURATION = 0.5  # æœ€çŸ­è¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
SILENCE_AFTER_SPEECH = 1.5  # è¯´å®Œåé™éŸ³å¤šä¹…åœæ­¢å½•éŸ³ï¼ˆç§’ï¼‰
MAX_RECORDING_DURATION = 30  # æœ€å¤§å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰

# Claude ç³»ç»Ÿæç¤ºè¯ï¼ˆä¼˜åŒ–è¯­éŸ³è¾“å‡ºï¼‰
SYSTEM_PROMPT = """ä½ æ˜¯ Speekium æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼Œè¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. ç”¨å£è¯­åŒ–çš„ä¸­æ–‡å›ç­”ï¼Œé€‚åˆæœ—è¯»
2. ä¸è¦ä½¿ç”¨ markdown æ ¼å¼ã€ä»£ç å—ã€åˆ—è¡¨ç¬¦å·
3. ä¸è¦ä½¿ç”¨ç‰¹æ®Šç¬¦å·å¦‚ *ã€#ã€`ã€- ç­‰
4. æ•°å­—ç”¨ä¸­æ–‡è¡¨è¾¾ï¼Œå¦‚"ä¸‰ç‚¹äº”"è€Œä¸æ˜¯"3.5"
5. è¯­æ°”è‡ªç„¶å‹å¥½ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ ·"""


class VoiceAssistant:
    def __init__(self):
        self.asr_model = None
        self.vad_model = None

    def load_asr(self):
        if self.asr_model is None:
            print("ğŸ”„ åŠ è½½ SenseVoice æ¨¡å‹...", flush=True)
            from funasr import AutoModel
            self.asr_model = AutoModel(model=ASR_MODEL, device="cpu")
            print("âœ… SenseVoice æ¨¡å‹åŠ è½½å®Œæˆ", flush=True)
        return self.asr_model

    def load_vad(self):
        if self.vad_model is None:
            print("ğŸ”„ åŠ è½½ VAD æ¨¡å‹...", flush=True)
            self.vad_model, _ = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad',
                force_reload=False,
                trust_repo=True
            )
            print("âœ… VAD æ¨¡å‹åŠ è½½å®Œæˆ", flush=True)
        return self.vad_model

    def record_with_vad(self):
        """ä½¿ç”¨ VAD æ£€æµ‹è¯­éŸ³ï¼Œè‡ªåŠ¨å¼€å§‹å’Œåœæ­¢å½•éŸ³"""
        model = self.load_vad()
        model.reset_states()  # é‡ç½® VAD çŠ¶æ€

        print("\nğŸ‘‚ æ­£åœ¨è†å¬...", flush=True)

        chunk_size = 512  # Silero VAD éœ€è¦ 512 samples @ 16kHz
        frames = []
        is_speaking = False
        silence_chunks = 0
        speech_chunks = 0
        consecutive_speech = 0  # è¿ç»­æ£€æµ‹åˆ°è¯­éŸ³çš„æ¬¡æ•°
        max_silence_chunks = int(SILENCE_AFTER_SPEECH * SAMPLE_RATE / chunk_size)
        min_speech_chunks = int(MIN_SPEECH_DURATION * SAMPLE_RATE / chunk_size)
        max_chunks = int(MAX_RECORDING_DURATION * SAMPLE_RATE / chunk_size)

        # é¢„ç¼“å†²ï¼šä¿ç•™è¯­éŸ³å¼€å§‹å‰çš„éŸ³é¢‘ï¼Œé¿å…ä¸¢å¤±å¼€å¤´
        pre_buffer_size = int(VAD_PRE_BUFFER * SAMPLE_RATE / chunk_size)
        pre_buffer = deque(maxlen=pre_buffer_size)

        recording_done = False

        def callback(indata, frame_count, time_info, status):
            nonlocal is_speaking, silence_chunks, speech_chunks, consecutive_speech, recording_done

            if recording_done:
                return

            try:
                audio_chunk = indata[:, 0].copy()

                # VAD æ£€æµ‹
                audio_tensor = torch.from_numpy(audio_chunk).float()
                speech_prob = model(audio_tensor, SAMPLE_RATE).item()

                if speech_prob > VAD_THRESHOLD:
                    # æ£€æµ‹åˆ°è¯­éŸ³
                    consecutive_speech += 1

                    if not is_speaking and consecutive_speech >= VAD_CONSECUTIVE_THRESHOLD:
                        is_speaking = True
                        # å°†é¢„ç¼“å†²çš„éŸ³é¢‘æ·»åŠ åˆ° framesï¼Œé¿å…ä¸¢å¤±è¯­éŸ³å¼€å¤´
                        frames.extend(pre_buffer)
                        pre_buffer.clear()
                        print(f"ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•éŸ³...", flush=True)

                    if is_speaking:
                        # åªæœ‰è¿ç»­æ£€æµ‹åˆ°è¯­éŸ³æ‰é‡ç½®é™éŸ³è®¡æ•°
                        if consecutive_speech >= VAD_CONSECUTIVE_THRESHOLD:
                            silence_chunks = 0
                        speech_chunks += 1
                        frames.append(audio_chunk)
                    else:
                        # è¿˜æœªç¡®è®¤å¼€å§‹è¯´è¯ï¼Œç»§ç»­å¡«å……é¢„ç¼“å†²
                        pre_buffer.append(audio_chunk)
                else:
                    # é™éŸ³
                    consecutive_speech = 0  # é‡ç½®è¿ç»­è¯­éŸ³è®¡æ•°

                    if is_speaking:
                        frames.append(audio_chunk)
                        silence_chunks += 1

                        # è¯´å®Œåé™éŸ³è¶³å¤Ÿé•¿ï¼Œåœæ­¢å½•éŸ³
                        if silence_chunks >= max_silence_chunks and speech_chunks >= min_speech_chunks:
                            recording_done = True
                            print("ğŸ”‡ è¯­éŸ³ç»“æŸ", flush=True)
                    else:
                        # è¿˜æœªå¼€å§‹è¯´è¯ï¼Œç»§ç»­å¡«å……é¢„ç¼“å†²
                        pre_buffer.append(audio_chunk)

                # è¶…è¿‡æœ€å¤§æ—¶é•¿
                if len(frames) >= max_chunks:
                    recording_done = True
                    print("â±ï¸ è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿", flush=True)

            except Exception as e:
                print(f"âš ï¸ VAD å¤„ç†é”™è¯¯: {e}", flush=True)
                recording_done = True

        with sd.InputStream(
            samplerate=SAMPLE_RATE, channels=1, dtype=np.float32,
            blocksize=chunk_size, callback=callback
        ):
            while not recording_done:
                sd.sleep(50)

        if not frames or speech_chunks < min_speech_chunks:
            return None

        audio = np.concatenate(frames)
        print(f"âœ… å½•éŸ³å®Œæˆ ({len(audio)/SAMPLE_RATE:.1f}ç§’)", flush=True)
        return audio

    def transcribe(self, audio):
        print("ğŸ”„ è¯†åˆ«ä¸­...", flush=True)
        model = self.load_asr()
        tmp_file = None

        try:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                tmp_file = f.name
                audio_int16 = (audio * 32767).astype(np.int16)
                write_wav(tmp_file, SAMPLE_RATE, audio_int16)
                result = model.generate(input=tmp_file)
                text = result[0]["text"] if result else ""
        finally:
            if tmp_file and os.path.exists(tmp_file):
                os.remove(tmp_file)

        # æ¸…ç† SenseVoice è¾“å‡ºçš„æ ‡ç­¾ï¼Œå¦‚ <|yue|><|EMO_UNKNOWN|><|Speech|>
        text = re.sub(r'<\|[^|]+\|>', '', text).strip()

        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}", flush=True)
        return text

    def ask_claude(self, question):
        """éæµå¼è°ƒç”¨ Claude"""
        print("ğŸ¤– Claude æ€è€ƒä¸­...", flush=True)
        try:
            result = subprocess.run(
                [
                    "claude", "-p", question,
                    "--dangerously-skip-permissions",
                    "--system-prompt", SYSTEM_PROMPT
                ],
                capture_output=True, text=True, timeout=120
            )
            response = result.stdout.strip()
            print(f"ğŸ’¬ Claude: {response}", flush=True)
            return response
        except subprocess.TimeoutExpired:
            return "æŠ±æ­‰ï¼Œå›å¤è¶…æ—¶äº†"
        except Exception as e:
            return f"å‡ºé”™äº†: {e}"

    async def ask_claude_stream(self, question):
        """æµå¼è°ƒç”¨ Claudeï¼Œè¿”å›å¥å­ç”Ÿæˆå™¨"""
        print("ğŸ¤– Claude æ€è€ƒä¸­...", flush=True)

        cmd = [
            "claude", "-p", question,
            "--dangerously-skip-permissions",
            "--system-prompt", SYSTEM_PROMPT,
            "--output-format", "stream-json",
            "--include-partial-messages",
            "--verbose"
        ]

        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        buffer = ""
        sentence_endings = re.compile(r'([ã€‚ï¼ï¼Ÿ\n])')

        async for line in process.stdout:
            try:
                data = json.loads(line.decode('utf-8'))

                # æå–æµå¼æ–‡æœ¬ç‰‡æ®µ
                if data.get("type") == "stream_event":
                    event = data.get("event", {})
                    if event.get("type") == "content_block_delta":
                        delta = event.get("delta", {})
                        if delta.get("type") == "text_delta":
                            text = delta.get("text", "")
                            buffer += text

                            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´å¥å­
                            while True:
                                match = sentence_endings.search(buffer)
                                if match:
                                    end_pos = match.end()
                                    sentence = buffer[:end_pos].strip()
                                    buffer = buffer[end_pos:]
                                    if sentence:
                                        print(f"ğŸ—£ï¸  {sentence}", flush=True)
                                        yield sentence
                                else:
                                    break

            except json.JSONDecodeError:
                continue
            except Exception as e:
                print(f"âš ï¸ è§£æé”™è¯¯: {e}", flush=True)
                continue

        # å¤„ç†å‰©ä½™å†…å®¹
        if buffer.strip():
            print(f"ğŸ—£ï¸  {buffer.strip()}", flush=True)
            yield buffer.strip()

        await process.wait()

    async def generate_audio(self, text):
        """ç”Ÿæˆ TTS éŸ³é¢‘æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„"""
        try:
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
                tmp_file = f.name
                communicate = edge_tts.Communicate(text, TTS_VOICE, rate=TTS_RATE)
                await communicate.save(tmp_file)
                return tmp_file
        except Exception as e:
            print(f"âš ï¸ TTS ç”Ÿæˆå¤±è´¥: {e}", flush=True)
            return None

    async def play_audio(self, tmp_file, delete=True):
        """æ’­æ”¾éŸ³é¢‘æ–‡ä»¶ï¼ˆå¼‚æ­¥ï¼Œè·¨å¹³å°ï¼‰ï¼Œå¯é€‰æ˜¯å¦åˆ é™¤"""
        if tmp_file and os.path.exists(tmp_file):
            try:
                system = platform.system()
                if system == "Darwin":  # macOS
                    cmd = ["afplay", tmp_file]
                elif system == "Linux":
                    cmd = ["ffplay", "-nodisp", "-autoexit", "-loglevel", "quiet", tmp_file]
                elif system == "Windows":
                    cmd = ["powershell", "-c", f"(New-Object Media.SoundPlayer '{tmp_file}').PlaySync()"]
                else:
                    print(f"âš ï¸ ä¸æ”¯æŒçš„å¹³å°: {system}", flush=True)
                    return

                process = await asyncio.create_subprocess_exec(*cmd)
                await process.wait()
            finally:
                if delete:
                    os.remove(tmp_file)

    async def speak(self, text):
        """TTS æœ—è¯»ï¼ˆå•å¥ï¼‰"""
        tmp_file = await self.generate_audio(text)
        await self.play_audio(tmp_file)

    async def chat_once(self):
        """å•æ¬¡å¯¹è¯"""
        audio = self.record_with_vad()

        if audio is None:
            return False  # æ²¡æœ‰æ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³

        text = self.transcribe(audio)
        if not text:
            print("âš ï¸  æœªè¯†åˆ«åˆ°å†…å®¹", flush=True)
            return True

        if USE_STREAMING:
            # æµå¼è¾“å‡º
            print("ğŸ”Š æµå¼æœ—è¯»ä¸­...", flush=True)
            audio_queue = asyncio.Queue()

            async def generate_worker():
                async for sentence in self.ask_claude_stream(text):
                    if sentence:
                        audio_file = await self.generate_audio(sentence)
                        if audio_file:
                            await audio_queue.put(audio_file)
                await audio_queue.put(None)

            async def play_worker():
                while True:
                    audio_file = await audio_queue.get()
                    if audio_file is None:
                        break
                    await self.play_audio(audio_file)

            await asyncio.gather(generate_worker(), play_worker())
        else:
            # éæµå¼è¾“å‡º
            response = self.ask_claude(text)
            await self.speak(response)

        return True

    async def run(self):
        print("=" * 50, flush=True)
        print("ğŸ™ï¸  Speekium å·²å¯åŠ¨ (æŒç»­å¯¹è¯æ¨¡å¼)", flush=True)
        print("   ä½¿ç”¨ VAD è‡ªåŠ¨æ£€æµ‹è¯­éŸ³", flush=True)
        if USE_STREAMING:
            print("   æ¨¡å¼: æµå¼è¾“å‡ºï¼ˆè¾¹ç”Ÿæˆè¾¹æœ—è¯»ï¼‰", flush=True)
        print("   Ctrl+C é€€å‡º", flush=True)
        print("=" * 50, flush=True)

        # é¢„åŠ è½½æ¨¡å‹
        self.load_vad()
        self.load_asr()

        print("\nğŸ§ å‡†å¤‡å°±ç»ªï¼Œè¯·å¼€å§‹è¯´è¯...\n", flush=True)

        try:
            while True:
                await self.chat_once()
                # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…ç«‹å³å¼€å§‹ä¸‹ä¸€è½®
                await asyncio.sleep(0.5)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§!", flush=True)


async def main():
    assistant = VoiceAssistant()
    await assistant.run()


if __name__ == "__main__":
    asyncio.run(main())
